\section{Probabilistic Graphical Models}
Probabilistic Graphical Models are models for which a graph can express the
conditional dependence structure between random variables. We will define
the basics used to understand PGMs here. \\
For starters, a model is a set of probability distributions that may
have generated data. For example, a model could be the set of normal distributions
\begin{equation}
  \left\{ p(x) : p(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(x-\mu)^2}{2\sigma^2} \right), \mu \in \mathbb{R}, \sigma^2 \in \mathbb{R}^+\right\}
\end{equation}
A graphical model is defined to be a pair $(\mathcal{G}, \mathcal{P})$ where
$\mathcal{G}$ is a graph and $\mathcal{P}$ is a set of distributions which
factorizes according to $\mathcal{G}$. A graph $\mathcal{G} = (\mathbf{V}, \mathbf{E})$
consists of a set of vertices $\mathbf{V}$ and a set of edges $\mathbf{E}$.
Typically the vertices are random variables and the edges relate the random variables.\\
We say that random variable $X_i$ is conditionally independent of $X_j$ given a set of
variables $\mathbf{Z}$, and write this as: $X_i \indep X_j | \mathbf{Z}$.\\
\subsection{Graphoid Axioms}
Some properties of conditonal independence are as follows:
\begin{enumerate}
  \item $X_1 \indep X_2 | \mathbf{Z} \implies X_2 \indep X_1|\mathbf{Z}$ (symmetry)
  \item $X_1 \indep \left( X_2, X_3 \right) | \mathbf{Z} \implies X_1 \indep X_2|\mathbf{Z}$ (decomposition)
  \item $X_1 \indep \left( X_2, X_3 \right) | \mathbf{Z} \implies X_1 \indep X_2|\left(\mathbf{Z}, X_3\right)$ (weak union)
  \item $X_1 \indep X_2|\left(\mathbf{Z}, X_3\right) \,\, \& \,\, X_1 \indep X_3 | \mathbf{Z} \implies X_1 \indep \left(X_2, X_3 \right) | \mathbf{Z}$ (contraction)
  \item $X_1 \indep X_2 | \left(\mathbf{Z}, X_3\right) \,\, \& \,\, X_1 \indep X_3 | \left(\mathbf{Z}, X_2\right) \implies X_1 \indep \left(X_2, X_3\right)|\mathbf{Z}$ (intersection, for positive distributions)
\end{enumerate}
\subsection{Bayesian Networks}
Bayesian Networks are a type of PGM constructed from directed acyclic graphs.
A directed acyclic graph (DAG) is a graph $\mathcal{G} = (\mathbf{V}, \mathbf{E})$
such that $\mathbf{E}$ contains only directed edges ($\rightarrow)$ and there
does not exist a sequence of directed edges from $X_i$ to $X_i$ for all nodes
in the graph.\\
Due to the structure of the DAG, we can factorize the joint distribution
$p(\mathbf{x})$ with respect to the graph as:
\begin{equation}
  p(\mathbf{x}) = \prod_{i=1}^n p(x_i \, | \, pa(x_i, \mathcal{G}))
\end{equation}
Here, $pa(x_i, \mathcal{G})$ are the parents of $x_i$ with respect to graph $\mathcal{G}$.\\
Using this factorization, we can specify conditional independencies from the graph's structure.
We define three useful set construction operations for these networks:
\begin{equation}
  \begin{matrix}
    an(x_i, \mathcal{G}) \equiv \left\{ x_j \, | \, x_j \rightarrow \cdots \rightarrow x_i \in \mathcal{G} \right\} & (\textrm{ancestors of } x_i)\\
    de(x_i, \mathcal{G}) \equiv \left\{ x_j \, | \, x_j \leftarrow \cdots \leftarrow x_i \in \mathcal{G} \right\} & (\textrm{descendants of } x_i)\\
    nd(x_i, \mathcal{G}) \equiv \left\{ x_j \, | \, x_j \notin de(x_i, \mathcal{G}) \right\} & (\textrm{non-descendants of } x_i)\\
  \end{matrix}
\end{equation}
A distribution $p(\mathbf{x})$ satisfies the local Markov property wrt DAG
$\mathcal{G}$ if:
\begin{equation}
  x_i \indep nd^*(x_i, \mathcal{G}) \, | \, pa(x_i, \mathcal{G})
\end{equation}
where $nd^*(x_i, \mathcal{G}) \equiv nd(x_i, \mathcal{G}) \setminus pa(x_i, \mathcal{G})$\\

\subsection{Markov Random Fields}
\subsection{Exact Inference}
\subsection{Variational Inference}
